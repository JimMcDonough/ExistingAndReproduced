{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd96e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Oreilly \n",
    "#https://www.oreilly.com/content/question-answering-with-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdda661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "import tarfile\n",
    "import json \n",
    "import hashlib\n",
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1026625",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_zip_file = r\"C:\\Users\\jimmc\\Documents\\UCSD_Bootcamp\\oreilly_QandA_example\\glove.6B.zip\"\n",
    "#glove_vectors_file = r\"C:\\Users\\jimmc\\Documents\\UCSD_Bootcamp\\oreilly_QandA_example\\glove.6B.50d.txt\"\n",
    "glove_vectors_file = r\"glove.6B.50d.txt\"  #either way works; if this is used the file gets exttracted from above zip\n",
    "\n",
    "data_set_zip = r\"C:\\Users\\jimmc\\Documents\\UCSD_Bootcamp\\oreilly_QandA_example\\tasks_1-20_v1-2.tar.gz\"\n",
    "\n",
    "#Select \"task 5\"\n",
    "train_set_file = \"qa5_three-arg-relations_train.txt\"\n",
    "test_set_file = \"qa5_three-arg-relations_test.txt\"\n",
    "\n",
    "train_set_post_file = \"tasks_1-20_v1-2/en/\"+train_set_file\n",
    "test_set_post_file = \"tasks_1-20_v1-2/en/\"+test_set_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8659d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: from urllib.request import urlretrieve, urlopen\n",
    "except ImportError: \n",
    "    from urllib import urlretrieve\n",
    "    from urllib2 import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a6956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#large file - 862 MB\n",
    "if (not os.path.isfile(glove_zip_file) and\n",
    "    not os.path.isfile(glove_vectors_file)):\n",
    "    urlretrieve (\"http://nlp.stanford.edu/data/glove.6B.zip\", \n",
    "                 glove_zip_file)\n",
    "if (not os.path.isfile(data_set_zip) and\n",
    "    not (os.path.isfile(train_set_file) and os.path.isfile(test_set_file))):\n",
    "    urlretrieve (\"https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\", \n",
    "                 data_set_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "854d835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_single_file(zip_file_name, output_file_name):\n",
    "    \"\"\"\n",
    "        If the output file is already created, don't recreate\n",
    "        If the output file does not exist, create it from the zipFile\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with open(output_file_name, 'wb') as out_file:\n",
    "            with zipfile.ZipFile(zip_file_name) as zipped:\n",
    "                for info in zipped.infolist():\n",
    "                    if output_file_name in info.filename:\n",
    "                        with zipped.open(info) as requested_file:\n",
    "                            out_file.write(requested_file.read())\n",
    "                            return\n",
    "                        \n",
    "def targz_unzip_single_file(zip_file_name, output_file_name, interior_relative_path):\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with tarfile.open(zip_file_name) as un_zipped:\n",
    "            un_zipped.extract(interior_relative_path+output_file_name)\n",
    "\n",
    "unzip_single_file(glove_zip_file, glove_vectors_file)\n",
    "targz_unzip_single_file(data_set_zip, train_set_file, \"tasks_1-20_v1-2/en/\")\n",
    "targz_unzip_single_file(data_set_zip, test_set_file, \"tasks_1-20_v1-2/en/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86376bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common practice is to replace all unknown tokens with a single <UNK> vector, but this isn’t always effective. \n",
    "#Instead, we can use randomization to draw a new vectorization for each unique unknown token.\n",
    "\n",
    "#The first time we run across a new unknown token, we simply draw a new vectorization from the (Gaussian-approximated) \n",
    "#distribution of the original GloVe vectorizations, and add that vectorization back to the GloVe word map. \n",
    "#To gather the distribution hyperparameters, Numpy has functions that automatically calculate variance and mean.\n",
    "#fill_unk will take care of giving us a new word vectorization whenever we need one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60b200fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize GloVe vectors\n",
    "glove_wordmap = {}\n",
    "with open(glove_vectors_file, \"r\", encoding=\"utf8\") as glove:\n",
    "    for line in glove:\n",
    "        name, vector = tuple(line.split(\" \", 1))  #split on first space\n",
    "        glove_wordmap[name] = np.fromstring(vector, sep=\" \")   #turn string into vector; spaces split the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4027a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be309e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvecs = []\n",
    "for item in glove_wordmap.items():\n",
    "    wvecs.append(item[1])\n",
    "s = np.vstack(wvecs)\n",
    "\n",
    "# Gather the distribution hyperparameters\n",
    "v = np.var(s,0) \n",
    "m = np.mean(s,0) \n",
    "RS = np.random.RandomState()\n",
    "\n",
    "def fill_unk(unk):\n",
    "    global glove_wordmap\n",
    "    glove_wordmap[unk] = RS.multivariate_normal(m,np.diag(v))\n",
    "    return glove_wordmap[unk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af420e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The limited vocabulary of bAbI tasks means the network can learn the relationships between words even without knowing \n",
    "#what the words mean. However, for speed of learning, we should choose vectorizations that have inherent meaning when \n",
    "#we can. To do this, we use a greedy search for words that exist in Stanford’s GLoVe word vectorization data set, and \n",
    "#if the word does not exist, then we fill in the entire word with an unknown, randomly created, new representation.\n",
    "\n",
    "#Under that model of word vectorization, we can define a new sentence2sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad2b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2sequence(sentence):\n",
    "    \"\"\"\n",
    "\n",
    "    - Turns an input paragraph into an (m,d) matrix, \n",
    "        where n(i think this is m) is the number of tokens in the sentence\n",
    "        and d is the number of dimensions each word vector has.\n",
    "\n",
    "      TensorFlow doesn't need to be used here, as simply\n",
    "      turning the sentence into a sequence based off our \n",
    "      mapping does not need the computational power that\n",
    "      TensorFlow provides. Normal Python suffices for this task.\n",
    "    \"\"\"\n",
    "    tokens = sentence.strip('\"(),-').lower().split(\" \")\n",
    "    rows = []\n",
    "    words = []\n",
    "    #Greedy search for tokens\n",
    "    for token in tokens:\n",
    "        i = len(token)\n",
    "        while len(token) > 0:      #search token and remove characters until none; then create randomized vector for unknown\n",
    "            word = token[:i]\n",
    "            if word in glove_wordmap:\n",
    "                rows.append(glove_wordmap[word])  #append vector from GloVe\n",
    "                words.append(word)   \n",
    "                token = token[i:]\n",
    "                i = len(token)\n",
    "                continue\n",
    "            else:\n",
    "                i = i-1\n",
    "            if i == 0:\n",
    "                # word OOV\n",
    "                # https://arxiv.org/pdf/1611.01436.pdf\n",
    "                rows.append(fill_unk(token))       #randomize vector for unknown word\n",
    "                words.append(token)\n",
    "                break\n",
    "    return np.array(rows), words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd57a6",
   "metadata": {},
   "source": [
    "Now we can package all the data together needed for each question, including the vectorization of the contexts, questions, and answers. In bAbI, contexts are defined by a numbered sequence of sentences, which contextualize deserializes into a list of sentences associated with one context. Questions and answers are on the same line, separated by tabs, so we can use tabs as a marker of whether a specific line refers to a question or not. When the numbering resets, future questions will refer to the new context (note that often there is more than one question corresponding to a single context). Answers also contain one other piece of information that we keep but don’t need to use: the number(s) corresponding to the sentences needed to answer the question, in the reference order. In our system, the network will teach itself which sentences are needed to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b3d0633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:19: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\jimmc\\AppData\\Local\\Temp\\ipykernel_19188\\2877034966.py:19: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if l is \"1\":\n"
     ]
    }
   ],
   "source": [
    "def contextualize(set_file):\n",
    "    \"\"\"\n",
    "    Read in the dataset of questions and build question+answer -> context sets.\n",
    "    Output is a list of data points, each of which is a 7-element tuple containing:\n",
    "        The sentences in the context in vectorized form.\n",
    "        The sentences in the context as a list of string tokens.\n",
    "        The question in vectorized form.\n",
    "        The question as a list of string tokens.\n",
    "        The answer in vectorized form.\n",
    "        The answer as a list of string tokens.\n",
    "        A list of numbers for supporting statements, which is currently unused.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    context = []\n",
    "    with open(set_file, \"r\", encoding=\"utf8\") as train:\n",
    "        for line in train:\n",
    "            l, ine = tuple(line.split(\" \", 1))\n",
    "            # Split the line numbers from the sentences they refer to.\n",
    "            if l is \"1\":\n",
    "                # New contexts always start with 1, \n",
    "                # so this is a signal to reset the context.\n",
    "                context = []\n",
    "            if \"\\t\" in ine: \n",
    "                # Tabs are the separator between questions and answers,\n",
    "                # and are not present in context statements.\n",
    "                question, answer, support = tuple(ine.split(\"\\t\"))\n",
    "                data.append((tuple(zip(*context))+\n",
    "                             sentence2sequence(question)+\n",
    "                             sentence2sequence(answer)+\n",
    "                             ([int(s) for s in support.split()],)))\n",
    "                # Multiple questions may refer to the same context, so we don't reset it.\n",
    "            else:\n",
    "                # Context sentence.\n",
    "                context.append(sentence2sequence(ine[:-1]))\n",
    "    return data\n",
    "train_data = contextualize(train_set_post_file)\n",
    "test_data = contextualize(test_set_post_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eeb3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[0][0]  #use to explore the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dd94818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.concatenate(train_data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8cd9ab",
   "metadata": {},
   "source": [
    "accumulate()\n",
    "itertools.accumulate(iterable[, func])\n",
    "This function makes an iterator that returns the results of a function. Functions can be passed around very much like variables. The accumulate() function takes a function as an argument. It also takes an iterable. It returns the accumulated results. The results are themselves contained in an iterable. This may all sound very confusing. I assure you that, when you play with the code it will make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81341c",
   "metadata": {},
   "source": [
    "lengths = itertools.accumulate(len(cvec) for cvec in train_data[0][0])\n",
    "for l in lengths:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21cbf0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79dbe7",
   "metadata": {},
   "source": [
    "context_words = sum(train_data[0][1],[])\n",
    "print(context_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "627e0f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmc\\AppData\\Local\\Temp\\ipykernel_19188\\3347106528.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(final_data)\n"
     ]
    }
   ],
   "source": [
    "final_train_data = []\n",
    "def finalize(data):\n",
    "    \"\"\"\n",
    "    Prepares data generated by contextualize() for use in the network.\n",
    "    \"\"\"\n",
    "    final_data = []\n",
    "    for cqas in train_data:\n",
    "        contextvs, contextws, qvs, qws, avs, aws, spt = cqas\n",
    "\n",
    "        lengths = itertools.accumulate(len(cvec) for cvec in contextvs)   #needed to keep track of end of sentences\n",
    "        context_vec = np.concatenate(contextvs)   #combine all arrays for the sentences\n",
    "        context_words = sum(contextws,[])  #turns sentence token lists into one list of all tokens\n",
    "\n",
    "        # Location markers for the beginnings of new sentences.\n",
    "        sentence_ends = np.array(list(lengths))       \n",
    "        final_data.append((context_vec, sentence_ends, qvs, spt, context_words, cqas, avs, aws))\n",
    "    return np.array(final_data)\n",
    "final_train_data = finalize(train_data)   \n",
    "final_test_data = finalize(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13137b0",
   "metadata": {},
   "source": [
    "At this point, we have fully prepared our training data and our testing data. The next task is to construct the network we’ll use to understand the data. Let’s start by clearing out the TensorFlow default graph so we always have the option to run the network again if we want to change something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6c42427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jimmc\\Documents\\UCSD_Bootcamp\\oreilly_QandA_example\\.env\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45dc4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()   #the above import and disable allowed to run;  I believe its a version 1 to version 2 error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd130d2",
   "metadata": {},
   "source": [
    "Since this is the beginning of the actual network, let’s also define all the constants we’ll need for the network. We call these “hyperparameters,” as they define how the network looks and trains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "076badbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "# The number of dimensions used to store data passed between recurrent layers in the network.\n",
    "recurrent_cell_size = 128\n",
    "\n",
    "# The number of dimensions in our word vectorizations.\n",
    "D = 50 \n",
    "\n",
    "# How quickly the network learns. Too high, and we may run into numeric instability \n",
    "# or other issues.\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Dropout probabilities. For a description of dropout and what these probabilities are, \n",
    "# see Entailment with TensorFlow.\n",
    "input_p, output_p = 0.5, 0.5\n",
    "\n",
    "# How many questions we train on at a time.\n",
    "batch_size = 128\n",
    "\n",
    "# Number of passes in episodic memory. We'll get to this later.\n",
    "passes = 4\n",
    "\n",
    "# Feed Forward layer sizes: the number of dimensions used to store data passed from feed-forward layers.\n",
    "ff_hidden_size = 256\n",
    "\n",
    "weight_decay = 0.00000001\n",
    "# The strength of our regularization. Increase to encourage sparsity in episodic memory, \n",
    "# but makes training slower. Don't make this larger than leraning_rate.\n",
    "\n",
    "training_iterations_count = 400000\n",
    "# How many questions the network trains on each time it is trained. \n",
    "# Some questions are counted multiple times.\n",
    "\n",
    "display_step = 100\n",
    "# How many iterations of training occur before each validation check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa593b2",
   "metadata": {},
   "source": [
    "With the hyperparameters out of the way, let’s describe the network structure. The structure of this network is split loosely into four modules and is described in Ask Me Anything: Dynamic Memory Networks for Natural Language Processing.\n",
    "\n",
    "The network is designed around having a recurrent layer’s memory be set dynamically, based on other information in the text, hence the name dynamic memory network (DMN). DMNs are loosely based on an understanding of how a human tries to answer a reading-comprehension-type question. The person gets a chance, first of all, to read the context and create memories of the facts inside. With those facts in mind, they then read the question, and re-examine the context specifically searching for the answer to that question, comparing the question to each of the facts.\n",
    "\n",
    "Sometimes, one fact guides us to another. In the bAbI data set, the network might want to find the location of a football. It might search for sentences about the football to find that John was the last person to touch the football, then search for sentences about John to find that John had been in both the bedroom and the hallway. Once it realizes that John had been last in the hallway, it can then answer the question and confidently say that the football is in the hallway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c66e83c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jimmc\\AppData\\Local\\Temp\\ipykernel_19188\\3784644438.py:24: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\jimmc\\Documents\\UCSD_Bootcamp\\oreilly_QandA_example\\.env\\lib\\site-packages\\keras\\layers\\rnn\\legacy_cells.py:588: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\jimmc\\Documents\\UCSD_Bootcamp\\oreilly_QandA_example\\.env\\lib\\site-packages\\keras\\layers\\rnn\\legacy_cells.py:602: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmc\\AppData\\Local\\Temp\\ipykernel_19188\\3784644438.py:15: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  input_gru = tf.compat.v1.nn.rnn_cell.GRUCell(recurrent_cell_size)\n"
     ]
    }
   ],
   "source": [
    "# Input Module\n",
    "\n",
    "# Context: A [batch_size, maximum_context_length, word_vectorization_dimensions] tensor \n",
    "# that contains all the context information.\n",
    "context = tf.placeholder(tf.float32, [None, None, D], \"context\")  \n",
    "context_placeholder = context # I use context as a variable name later on\n",
    "\n",
    "# input_sentence_endings: A [batch_size, maximum_sentence_count, 2] tensor that \n",
    "# contains the locations of the ends of sentences. \n",
    "input_sentence_endings = tf.placeholder(tf.int32, [None, None, 2], \"sentence\")\n",
    "\n",
    "# recurrent_cell_size: the number of hidden units in recurrent layers.\n",
    "#input_gru = tf.contrib.rnn.GRUCell(recurrent_cell_size)   #this code doesn't work in Version 2 tensoflow\n",
    "#input_gru = tf.nn.rnn_cell.GRUCell(recurrent_cell_size) \n",
    "input_gru = tf.compat.v1.nn.rnn_cell.GRUCell(recurrent_cell_size)\n",
    "\n",
    "# input_p: The probability of maintaining a specific hidden input unit.\n",
    "# Likewise, output_p is the probability of maintaining a specific hidden output unit.\n",
    "gru_drop = tf.compat.v1.nn.rnn_cell.DropoutWrapper(input_gru, input_p, output_p)\n",
    "\n",
    "\n",
    "# dynamic_rnn also returns the final internal state. We don't need that, and can\n",
    "# ignore the corresponding output (_). \n",
    "input_module_outputs, _ = tf.nn.dynamic_rnn(gru_drop, context, dtype=tf.float32, scope = \"input_module\")\n",
    "\n",
    "# cs: the facts gathered from the context.\n",
    "cs = tf.gather_nd(input_module_outputs, input_sentence_endings)\n",
    "# to use every word as a fact, useful for tasks with one-sentence contexts\n",
    "s = input_module_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212939b3",
   "metadata": {},
   "source": [
    "The question module is the second module, and arguably the simplest. It consists of another GRU pass, this time over the text of the question. Instead of pieces of evidence, we can simply pass forward the end state, as the question is guaranteed by the data set to be one sentence long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20b0536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Module\n",
    "\n",
    "# query: A [batch_size, maximum_question_length, word_vectorization_dimensions] tensor \n",
    "#  that contains all of the questions.\n",
    "\n",
    "query = tf.placeholder(tf.float32, [None, None, D], \"query\")\n",
    "\n",
    "# input_query_lengths: A [batch_size, 2] tensor that contains question length information. \n",
    "# input_query_lengths[:,1] has the actual lengths; input_query_lengths[:,0] is a simple range() \n",
    "# so that it plays nice with gather_nd.\n",
    "input_query_lengths = tf.placeholder(tf.int32, [None, 2], \"query_lengths\")\n",
    "\n",
    "question_module_outputs, _ = tf.nn.dynamic_rnn(gru_drop, query, dtype=tf.float32, \n",
    "                                               scope = tf.VariableScope(True, \"input_module\"))\n",
    "\n",
    "# q: the question states. A [batch_size, recurrent_cell_size] tensor.\n",
    "q = tf.gather_nd(question_module_outputs, input_query_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8208a84a",
   "metadata": {},
   "source": [
    "Our third module, the episodic memory module, is where things begin to get interesting. It uses attention to do multiple passes, each pass consisting of GRUs iterating over the input. Each iteration inside each pass has a weighted update on current memory, based on how much attention is being paid to the corresponding fact at that time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e30fd",
   "metadata": {},
   "source": [
    "Attention in neural networks was originally designed for image analysis, especially for cases where parts of the image are far more relevant than others. Networks use attention to determine the best locations in which to do further analysis when performing tasks, such as finding locations of objects in images, tracking objects that move between images, facial recognition, or other tasks that benefit from finding the most pertinent information for the task within the image.\n",
    "\n",
    "The main problem is that attention, or at least hard attention (which attends to exactly one input location) is not easily optimizable. As with most other neural networks, our optimization scheme is to compute the derivative of a loss function with respect to our inputs and weights, and hard attention is simply not differentiable, thanks to its binary nature. Instead, we are forced to use the real-valued version known as “soft attention,” which combines all the input locations that could be attended to using some form of weighting. Thankfully, the weighting is fully differentiable and can be trained normally. While it is possible to learn hard attention, it’s much more difficult and sometimes performs worse than soft attention. Thus, we’ll stick with soft attention for this model. Don’t worry about coding the derivative; TensorFlow’s optimization schemes do it for us.\n",
    "\n",
    "We calculate attention in this model by constructing similarity measures between each fact, our current memory, and the original question. (Note that this is different from normal attention, which only constructs similarity measures between facts and current memory.) We pass the results through a two-layer feed-forward network to get an attention constant for each fact. We then modify the memory by doing a weighted pass with a GRU over the input facts (weighted by the corresponding attention constant). In order to avoid adding incorrect information into memory when the context is shorter than the full length of the matrix, we create a mask for which facts exist and don’t attend at all (i.e., retain the same memory) when the fact does not exist.\n",
    "\n",
    "Another notable aspect is that the attention mask is nearly always wrapped around a representation used by a layer. For images, that wrapping is most likely to happen around a convolutional layer (most likely one with a direct mapping to locations in the image), and for natural language, that wrapping is most likely to happen around a recurrent layer. Wrapping attention around a feed-forward layer, while technically possible, is usually not useful—at least not in a way that can’t be more easily simulated by further feed-forward layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f74b2a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jimmc\\Documents\\UCSD_Bootcamp\\oreilly_QandA_example\\.env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: calling count_nonzero (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmc\\AppData\\Local\\Temp\\ipykernel_19188\\3151297477.py:85: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  attention_gru = tf.compat.v1.nn.rnn_cell.GRUCell(recurrent_cell_size)\n"
     ]
    }
   ],
   "source": [
    "# Episodic Memory\n",
    "\n",
    "# make sure the current memory (i.e. the question vector) is broadcasted along the facts dimension\n",
    "size = tf.stack([tf.constant(1),tf.shape(cs)[1], tf.constant(1)])\n",
    "re_q = tf.tile(tf.reshape(q,[-1,1,recurrent_cell_size]),size)\n",
    "\n",
    "\n",
    "# Final output for attention, needs to be 1 in order to create a mask\n",
    "output_size = 1 \n",
    "\n",
    "# Weights and biases\n",
    "attend_init = tf.random_normal_initializer(stddev=0.1)\n",
    "w_1 = tf.get_variable(\"attend_w1\", [1,recurrent_cell_size*7, recurrent_cell_size], \n",
    "                      tf.float32, initializer = attend_init)\n",
    "w_2 = tf.get_variable(\"attend_w2\", [1,recurrent_cell_size, output_size], \n",
    "                      tf.float32, initializer = attend_init)\n",
    "\n",
    "b_1 = tf.get_variable(\"attend_b1\", [1, recurrent_cell_size], \n",
    "                      tf.float32, initializer = attend_init)\n",
    "b_2 = tf.get_variable(\"attend_b2\", [1, output_size], \n",
    "                      tf.float32, initializer = attend_init)\n",
    "\n",
    "# Regulate all the weights and biases\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(w_1))\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(b_1))\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(w_2))\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(b_2))\n",
    "\n",
    "def attention(c, mem, existing_facts):\n",
    "    \"\"\"\n",
    "    Custom attention mechanism.\n",
    "    c: A [batch_size, maximum_sentence_count, recurrent_cell_size] tensor \n",
    "        that contains all the facts from the contexts.\n",
    "    mem: A [batch_size, maximum_sentence_count, recurrent_cell_size] tensor that \n",
    "        contains the current memory. It should be the same memory for all facts for accurate results.\n",
    "    existing_facts: A [batch_size, maximum_sentence_count, 1] tensor that \n",
    "        acts as a binary mask for which facts exist and which do not.\n",
    "\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"attending\") as scope:\n",
    "        # attending: The metrics by which we decide what to attend to.\n",
    "        attending = tf.concat([c, mem, re_q, c * re_q,  c * mem, (c-re_q)**2, (c-mem)**2], 2)\n",
    "\n",
    "        # m1: First layer of multiplied weights for the feed-forward network. \n",
    "        #     We tile the weights in order to manually broadcast, since tf.matmul does not\n",
    "        #     automatically broadcast batch matrix multiplication as of TensorFlow 1.2.\n",
    "        m1 = tf.matmul(attending * existing_facts, \n",
    "                       tf.tile(w_1, tf.stack([tf.shape(attending)[0],1,1]))) * existing_facts\n",
    "        # bias_1: A masked version of the first feed-forward layer's bias\n",
    "        #     over only existing facts.\n",
    "\n",
    "        bias_1 = b_1 * existing_facts\n",
    "\n",
    "        # tnhan: First nonlinearity. In the original paper, this is a tanh nonlinearity; \n",
    "        #        choosing relu was a design choice intended to avoid issues with \n",
    "        #        low gradient magnitude when the tanh returned values close to 1 or -1. \n",
    "        tnhan = tf.nn.relu(m1 + bias_1)\n",
    "\n",
    "        # m2: Second layer of multiplied weights for the feed-forward network. \n",
    "        #     Still tiling weights for the same reason described in m1's comments.\n",
    "        m2 = tf.matmul(tnhan, tf.tile(w_2, tf.stack([tf.shape(attending)[0],1,1])))\n",
    "\n",
    "        # bias_2: A masked version of the second feed-forward layer's bias.\n",
    "        bias_2 = b_2 * existing_facts\n",
    "\n",
    "        # norm_m2: A normalized version of the second layer of weights, which is used \n",
    "        #     to help make sure the softmax nonlinearity doesn't saturate.\n",
    "        norm_m2 = tf.nn.l2_normalize(m2 + bias_2, -1)\n",
    "\n",
    "        # softmaxable: A hack in order to use sparse_softmax on an otherwise dense tensor. \n",
    "        #     We make norm_m2 a sparse tensor, then make it dense again after the operation.\n",
    "        softmax_idx = tf.where(tf.not_equal(norm_m2, 0))[:,:-1]\n",
    "        softmax_gather = tf.gather_nd(norm_m2[...,0], softmax_idx)\n",
    "        softmax_shape = tf.shape(norm_m2, out_type=tf.int64)[:-1]\n",
    "        softmaxable = tf.SparseTensor(softmax_idx, softmax_gather, softmax_shape)\n",
    "        return tf.expand_dims(tf.sparse_tensor_to_dense(tf.sparse_softmax(softmaxable)),-1)\n",
    "\n",
    "# facts_0s: a [batch_size, max_facts_length, 1] tensor \n",
    "#     whose values are 1 if the corresponding fact exists and 0 if not.\n",
    "facts_0s = tf.cast(tf.count_nonzero(input_sentence_endings[:,:,-1:],-1,keep_dims=True),tf.float32)\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"Episodes\") as scope:\n",
    "    #attention_gru = tf.contrib.rnn.GRUCell(recurrent_cell_size)\n",
    "    attention_gru = tf.compat.v1.nn.rnn_cell.GRUCell(recurrent_cell_size)\n",
    "    # memory: A list of all tensors that are the (current or past) memory state \n",
    "    #   of the attention mechanism.\n",
    "    memory = [q]\n",
    "\n",
    "    # attends: A list of all tensors that represent what the network attends to.\n",
    "    attends = []\n",
    "    for a in range(passes):\n",
    "        # attention mask\n",
    "        attend_to = attention(cs, tf.tile(tf.reshape(memory[-1],[-1,1,recurrent_cell_size]),size),\n",
    "                              facts_0s)\n",
    "\n",
    "        # Inverse attention mask, for what's retained in the state.\n",
    "        retain = 1-attend_to\n",
    "\n",
    "        # GRU pass over the facts, according to the attention mask.\n",
    "        while_valid_index = (lambda state, index: index < tf.shape(cs)[1])\n",
    "        update_state = (lambda state, index: (attend_to[:,index,:] * \n",
    "                                                 attention_gru(cs[:,index,:], state)[0] + \n",
    "                                                 retain[:,index,:] * state))\n",
    "        # start loop with most recent memory and at the first index\n",
    "        memory.append(tuple(tf.while_loop(while_valid_index,\n",
    "                          (lambda state, index: (update_state(state,index),index+1)),\n",
    "                           loop_vars = [memory[-1], 0]))[0]) \n",
    "\n",
    "        attends.append(attend_to)\n",
    "\n",
    "        # Reuse variables so the GRU pass uses the same variables every pass.\n",
    "        scope.reuse_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5f9d3",
   "metadata": {},
   "source": [
    "The final module is the answer module, which regresses from the question and episodic memory modules’ outputs using a fully connected layer to a “final result” word vector, and the word in the context that is closest in distance to that result is our final output (to guarantee the result is an actual word). We calculate the closest word by creating a “score” for each word, which indicates the final result’s distance from the word. While you can design an answer module that can return multiple words, it is not needed for the bAbI tasks we attempt in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0090d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Module\n",
    "\n",
    "# a0: Final memory state. (Input to answer module)\n",
    "a0 = tf.concat([memory[-1], q], -1)\n",
    "\n",
    "# fc_init: Initializer for the final fully connected layer's weights.\n",
    "fc_init = tf.random_normal_initializer(stddev=0.1) \n",
    "\n",
    "with tf.variable_scope(\"answer\"):\n",
    "    # w_answer: The final fully connected layer's weights.\n",
    "    w_answer = tf.get_variable(\"weight\", [recurrent_cell_size*2, D], \n",
    "                               tf.float32, initializer = fc_init)\n",
    "    # Regulate the fully connected layer's weights\n",
    "    tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, \n",
    "                     tf.nn.l2_loss(w_answer)) \n",
    "\n",
    "    # The regressed word. This isn't an actual word yet; \n",
    "    #    we still have to find the closest match.\n",
    "    logit = tf.expand_dims(tf.matmul(a0, w_answer),1)\n",
    "\n",
    "    # Make a mask over which words exist.\n",
    "    with tf.variable_scope(\"ending\"):\n",
    "        all_ends = tf.reshape(input_sentence_endings, [-1,2])\n",
    "        range_ends = tf.range(tf.shape(all_ends)[0])\n",
    "        ends_indices = tf.stack([all_ends[:,0],range_ends], axis=1)\n",
    "        ind = tf.reduce_max(tf.scatter_nd(ends_indices, all_ends[:,1],\n",
    "                                          [tf.shape(q)[0], tf.shape(all_ends)[0]]),\n",
    "                            axis=-1)\n",
    "        range_ind = tf.range(tf.shape(ind)[0])\n",
    "        mask_ends = tf.cast(tf.scatter_nd(tf.stack([ind, range_ind], axis=1), \n",
    "                                          tf.ones_like(range_ind), [tf.reduce_max(ind)+1, \n",
    "                                                                    tf.shape(ind)[0]]), bool)\n",
    "        # A bit of a trick. With the locations of the ends of the mask (the last periods in \n",
    "        #  each of the contexts) as 1 and the rest as 0, we can scan with exclusive or \n",
    "        #  (starting from all 1). For each context in the batch, this will result in 1s \n",
    "        #  up until the marker (the location of that last period) and 0s afterwards.\n",
    "        mask = tf.scan(tf.logical_xor,mask_ends, tf.ones_like(range_ind, dtype=bool))\n",
    "\n",
    "    # We score each possible word inversely with their Euclidean distance to the regressed word.\n",
    "    #  The highest score (lowest distance) will correspond to the selected word.\n",
    "    logits = -tf.reduce_sum(tf.square(context*tf.transpose(tf.expand_dims(\n",
    "                    tf.cast(mask, tf.float32),-1),[1,0,2]) - logit), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d9f23",
   "metadata": {},
   "source": [
    "Gradient descent is the default optimizer for a neural network. Its goal is to decrease the network’s “loss,” which is a measure of how poorly the network performs. It does this by finding the derivative of loss with respect to each of the weights under the current input, and then “descends” the weights so they’ll reduce the loss. Most of the time, this works well enough, but often it’s not ideal. There are various schemes that use “momentum” or other approximations of the more direct path to the optimal weights. One of the most useful of these optimization schemes is known as adaptive moment estimation, or Adam.\n",
    "\n",
    "Adam estimates the first two moments of the gradient by calculating an exponentially decaying average of past iterations’ gradients and squared gradients, which correspond to the estimated mean and the estimated variance of these gradients. The calculations use two additional hyperparameters to indicate how quickly the averages decay with the addition of new information. The averages are initialized as zero, which leads to bias toward zero, especially when those hyperparameters near one.\n",
    "\n",
    "In order to counteract that bias, Adam computes bias-corrected moment estimates that are greater in magnitude than the originals. The corrected estimates are then used to update the weights throughout the network. The combination of these estimates make Adam one of the best choices overall for optimization, especially for complex networks. This applies doubly to data that is very sparse, such as is common in natural language processing tasks.\n",
    "\n",
    "In TensorFlow, we can use Adam by creating a tf.train.AdamOptimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29bac7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jimmc\\Documents\\UCSD_Bootcamp\\oreilly_QandA_example\\.env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# gold_standard: The real answers.\n",
    "gold_standard = tf.placeholder(tf.float32, [None, 1, D], \"answer\")\n",
    "with tf.variable_scope('accuracy'):\n",
    "    eq = tf.equal(context, gold_standard)\n",
    "    corrbool = tf.reduce_all(eq,-1)\n",
    "    logloc = tf.reduce_max(logits, -1, keep_dims = True)\n",
    "    # locs: A boolean tensor that indicates where the score \n",
    "    #  matches the minimum score. This happens on multiple dimensions, \n",
    "    #  so in the off chance there's one or two indexes that match \n",
    "    #  we make sure it matches in all indexes.\n",
    "    locs = tf.equal(logits, logloc)\n",
    "\n",
    "    # correctsbool: A boolean tensor that indicates for which \n",
    "    #   words in the context the score always matches the minimum score.\n",
    "    correctsbool = tf.reduce_any(tf.logical_and(locs, corrbool), -1)\n",
    "    # corrects: A tensor that is simply correctsbool cast to floats.\n",
    "    corrects = tf.where(correctsbool, tf.ones_like(correctsbool, dtype=tf.float32), \n",
    "                        tf.zeros_like(correctsbool,dtype=tf.float32))\n",
    "\n",
    "    # corr: corrects, but for the right answer instead of our selected answer.\n",
    "    corr = tf.where(corrbool, tf.ones_like(corrbool, dtype=tf.float32), \n",
    "                        tf.zeros_like(corrbool,dtype=tf.float32))\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    # Use sigmoid cross entropy as the base loss, \n",
    "    #  with our distances as the relative probabilities. There are\n",
    "    #  multiple correct labels, for each location of the answer word within the context.\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits = tf.nn.l2_normalize(logits,-1),\n",
    "                                                   labels = corr)\n",
    "\n",
    "    # Add regularization losses, weighted by weight_decay.\n",
    "    total_loss = tf.reduce_mean(loss) + weight_decay * tf.add_n(\n",
    "        tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "\n",
    "# TensorFlow's default implementation of the Adam optimizer works. We can adjust more than \n",
    "#  just the learning rate, but it's not necessary to find a very good optimum.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "# Once we have an optimizer, we ask it to minimize the loss \n",
    "#   in order to work towards the proper training.\n",
    "opt_op = optimizer.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d242c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the TensorFlow session\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f32a05b",
   "metadata": {},
   "source": [
    "With everything set and ready, we can begin batching our training data to train our network! While the system is training, we should check on how well the network is doing in terms of accuracy. We do this with a validation set, which is taken from testing data so it has no overlap with the training data.\n",
    "\n",
    "Using a validation set based on testing data allows us to get a better sense of how well the network can generalize what it learns and apply it to other contexts. If we validate on the training data, the network may overfit—in other words, learn specific examples and memorize the answers to them, which doesn’t help the network answer new questions.\n",
    "\n",
    "If you installed TQDM, you can use it to keep track of how long the network has been training and receive an estimate of when training will finish. You can stop the training at any time if you feel the results are good enough by interrupting the Jupyter Notebook kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45d30723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_batch(batch_data, more_data = False):\n",
    "    \"\"\"\n",
    "        Prepare all the preproccessing that needs to be done on a batch-by-batch basis.\n",
    "    \"\"\"\n",
    "    context_vec, sentence_ends, questionvs, spt, context_words, cqas, answervs, _ = zip(*batch_data)\n",
    "    ends = list(sentence_ends)\n",
    "    maxend = max(map(len, ends))\n",
    "    aends = np.zeros((len(ends), maxend))\n",
    "    for index, i in enumerate(ends):\n",
    "        for indexj, x in enumerate(i):\n",
    "            aends[index, indexj] = x-1\n",
    "    new_ends = np.zeros(aends.shape+(2,))\n",
    "\n",
    "    for index, x in np.ndenumerate(aends):\n",
    "        new_ends[index+(0,)] = index[0]\n",
    "        new_ends[index+(1,)] = x\n",
    "\n",
    "    contexts = list(context_vec)\n",
    "    max_context_length = max([len(x) for x in contexts])\n",
    "    contextsize = list(np.array(contexts[0]).shape)\n",
    "    contextsize[0] = max_context_length\n",
    "    final_contexts = np.zeros([len(contexts)]+contextsize)\n",
    "\n",
    "    contexts = [np.array(x) for x in contexts]\n",
    "    for i, context in enumerate(contexts):\n",
    "        final_contexts[i,0:len(context),:] = context\n",
    "    max_query_length = max(len(x) for x in questionvs)\n",
    "    querysize = list(np.array(questionvs[0]).shape)\n",
    "    querysize[:1] = [len(questionvs),max_query_length]\n",
    "    queries = np.zeros(querysize)\n",
    "    querylengths = np.array(list(zip(range(len(questionvs)),[len(q)-1 for q in questionvs])))\n",
    "    questions = [np.array(q) for q in questionvs]\n",
    "    for i, question in enumerate(questions):\n",
    "        queries[i,0:len(question),:] = question\n",
    "    data = {context_placeholder: final_contexts, input_sentence_endings: new_ends, \n",
    "                            query:queries, input_query_lengths:querylengths, gold_standard: answervs}\n",
    "    return (data, context_words, cqas) if more_data else data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30ce6c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0.0, Minibatch Loss=  0.67451864 Accuracy=  0.0\n",
      "Iter 100.0, Minibatch Loss=  0.6735304 Accuracy=  0.17734376\n",
      "Iter 200.0, Minibatch Loss=  0.67349577 Accuracy=  0.37890625\n"
     ]
    }
   ],
   "source": [
    "# Use TQDM if installed\n",
    "tqdm_installed = False\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    tqdm_installed = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Prepare validation set\n",
    "batch = np.random.randint(final_test_data.shape[0], size=batch_size*10)\n",
    "batch_data = final_test_data[batch]\n",
    "\n",
    "validation_set, val_context_words, val_cqas = prep_batch(batch_data, True)\n",
    "\n",
    "# training_iterations_count: The number of data pieces to train on in total\n",
    "# batch_size: The number of data pieces per batch\n",
    "def train(iterations, batch_size):\n",
    "    training_iterations = range(0,iterations,batch_size)\n",
    "    if tqdm_installed:\n",
    "        # Add a progress bar if TQDM is installed\n",
    "        training_iterations = tqdm(training_iterations)\n",
    "\n",
    "    wordz = []\n",
    "    for j in training_iterations:\n",
    "\n",
    "        batch = np.random.randint(final_train_data.shape[0], size=batch_size)\n",
    "        batch_data = final_train_data[batch]\n",
    "\n",
    "        sess.run([opt_op], feed_dict=prep_batch(batch_data))\n",
    "        if (j/batch_size) % display_step == 0:\n",
    "\n",
    "            # Calculate batch accuracy\n",
    "            acc, ccs, tmp_loss, log, con, cor, loc  = sess.run([corrects, cs, total_loss, logit,\n",
    "                                                                context_placeholder,corr, locs], \n",
    "                                                               feed_dict=validation_set)\n",
    "            # Display results\n",
    "            print(\"Iter \" + str(j/batch_size) + \", Minibatch Loss= \",tmp_loss,\n",
    "                  \"Accuracy= \", np.mean(acc))\n",
    "train(30000,batch_size) # Small amount of training for preliminary results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd7e133",
   "metadata": {},
   "source": [
    "After a little bit of training, let’s peek inside and see what kinds of answers we’re getting from the network. In the diagrams below, we visualize attention over each of the episodes (rows) for all the sentences (columns) in our context; darker colors represent more attention paid to that sentence on that episode.\n",
    "\n",
    "You should see attention change between at least two episodes for each question, but sometimes attention will be able to find the answer within one, and sometimes it will take all four episodes. If the attention appears to be blank, it may be saturating and paying attention to everything at once. In that case, you can try training with a higher weight_decay in order to discourage that from happening. Later on in training, saturation becomes extremely common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f324dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAG2CAYAAABYlw1sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgnklEQVR4nO3de3BUhdnH8d+SmA0hFwgQCIWAiFxTInIzUFEEjJEivl7gVagBEYsEBRGhmc4U07GEttIpNQiCCtoaQEXw0mqkCAEsKAQRUMSAUVJNREFCLrBAct4/HPY1DdZkWTw88fuZ2Zmcs3vOPpxJ4MvZs1mP4ziOAAAADGjk9gAAAAB1RbgAAAAzCBcAAGAG4QIAAMwgXAAAgBmECwAAMINwAQAAZhAuAADADMIFAACYQbgAAAAzLphwmTt3rjwej6ZNm+b2KAAA4AJ1QYTLtm3b9Pjjj6tnz55ujwIAAC5grodLeXm5xowZoyVLlqhZs2ZujwMAAC5goW4PkJ6eruHDh2vo0KF6+OGH/+tjfT6ffD6ff7m6ulpHjhxR8+bN5fF4zveoAAAgCBzHUVlZmdq0aaNGjep3DsXVcFmxYoV27Nihbdu21enxWVlZyszMPM9TAQCAH0JRUZHatm1br21cC5eioiJNnTpVa9euVXh4eJ22ycjI0PTp0/3LpaWlSkhI0MQVv1VYRN32gbPbd+SgusQmuD1Gg8CxDJ6/r1mjLs3buz2Gecdah+ryS3/q9hgNAj/fwXGy8oSW/O9vFBUVVe9tXQuX/Px8HTp0SJdffrl/XVVVlTZu3Kjs7Gz5fD6FhITU2Mbr9crr9dbaV1hEuLxNGp/3mRuy0BNejmGQcCyDp1FYqC7yhrk9hnmhjUP5ngwSfr6DK5DLPFwLlyFDhmj37t011o0fP15du3bVrFmzakULAACAa+ESFRWlxMTEGuuaNGmi5s2b11oPAAAgXQBvhwYAAKgr198O/W0bNmxwewQAAHAB44wLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAww9VwWbhwoXr27Kno6GhFR0crOTlZr732mpsjAQCAC5ir4dK2bVvNnTtX+fn52r59u6655hqNHDlS77//vptjAQCAC1Som08+YsSIGsu/+93vtHDhQm3dulU9evRwaSoAAHChcjVcvq2qqkrPP/+8KioqlJyc7PY4AADgAuR6uOzevVvJyck6ceKEIiMjtXr1anXv3v2sj/X5fPL5fP7lY8eOSZK+PnlCYa7/SWzzVZ3WEd9xt8doEDiWweOrquJYBkH5yRB9cPgTt8doEI6eKONYBsHpSt/3P+g7eBzHcYI4S72dPHlSBw8eVGlpqV544QU98cQTysvLO2u8PPTQQ8rMzKy1/vWC3WoSFfVDjNtgHfFVKtYb4fYYDQLHMng4lsHx5I7nFOtt7PYYDcIHhz9R9+Yd3B7DPF/FcS24YaZKS0sVHR1dr21dfzt0WFiYOnXqpN69eysrK0tJSUmaP3/+WR+bkZGh0tJS/62oqOgHnhYAALjpgnuBpbq6usbLQd/m9Xrl9Xp/4IkAAMCFwtVwycjIUGpqqhISElRWVqacnBxt2LBBubm5bo4FAAAuUK6Gy6FDh3THHXeouLhYMTEx6tmzp3JzczVs2DA3xwIAABcoV8PlySefdPPpAQCAMa5fnAsAAFBXhAsAADCDcAEAAGYQLgAAwAzCBQAAmEG4AAAAMwgXAABgBuECAADMIFwAAIAZhAsAADCDcAEAAGYQLgAAwAzCBQAAmEG4AAAAMwgXAABgBuECAADMIFwAAIAZhAsAADCDcAEAAGYQLgAAwAzCBQAAmEG4AAAAMwgXAABgBuECAADMIFwAAIAZhAsAADCDcAEAAGYQLgAAwAzCBQAAmEG4AAAAMwgXAABgBuECAADMIFwAAIAZhAsAADCDcAEAAGYQLgAAwAzCBQAAmEG4AAAAMwgXAABgBuECAADMIFwAAIAZhAsAADCDcAEAAGYQLgAAwAzCBQAAmEG4AAAAMwgXAABgBuECAADMIFwAAIAZhAsAADCDcAEAAGYQLgAAwAzCBQAAmEG4AAAAMwgXAABgBuECAADMIFwAAIAZhAsAADCDcAEAAGYQLgAAwAzCBQAAmEG4AAAAMwgXAABgRsDhsmnTJo0dO1bJycn67LPPJEl//etftXnz5qANBwAA8G0BhcuqVauUkpKixo0b691335XP55MklZaWas6cOUEdEAAA4IyAwuXhhx/WokWLtGTJEl100UX+9QMHDtSOHTuCNhwAAMC3BRQu+/bt06BBg2qtj4mJ0dGjR891JgAAgLMKKFxat26t/fv311q/efNmdezY8ZyHAgAAOJuAwmXixImaOnWq3n77bXk8Hn3++ed69tlnNWPGDN1zzz3BnhEAAECSFBrIRr/61a9UXV2tIUOGqLKyUoMGDZLX69WMGTN07733BntGAAAASQGGi8fj0a9//Ws9+OCD2r9/v8rLy9W9e3dFRkYGez4AAAC/gMLljLCwMHXv3j1YswAAAPxXdQ6Xm266qc47ffHFFwMaBgAA4L+p88W5MTEx/lt0dLTWrVun7du3++/Pz8/XunXrFBMTc14GBQAAqPMZl6VLl/q/njVrlkaNGqVFixYpJCREklRVVaXJkycrOjo6+FMCAAAowLdDP/XUU5oxY4Y/WiQpJCRE06dP11NPPRW04QAAAL4toHA5ffq0Pvzww1rrP/zwQ1VXV5/zUAAAAGcT0LuKxo8frwkTJujAgQPq16+fJOntt9/W3LlzNX78+KAOCAAAcEZA4fLII4+odevWmjdvnoqLiyVJ8fHxevDBB/XAAw8EdUAAAIAzAgqXRo0aaebMmZo5c6aOHTsmSVyUCwAAzrtz+gV0X375pfbt2ydJ6tq1q1q0aBGUoQAAAM4moItzKyoqdOeddyo+Pl6DBg3SoEGDFB8frwkTJqiysjLYMwIAAEgKMFymT5+uvLw8vfLKKzp69KiOHj2ql156SXl5efW6xiUrK0t9+/ZVVFSU4uLidOONN/rP4AAAAPyngMJl1apVevLJJ5Wamqro6GhFR0fr+uuv15IlS/TCCy/UeT95eXlKT0/X1q1btXbtWp06dUrXXnutKioqAhkLAAA0cAFd41JZWalWrVrVWh8XF1evl4pef/31GsvLli1TXFyc8vPzNWjQoEBGAwAADVhA4ZKcnKzZs2frmWeeUXh4uCTp+PHjyszMVHJycsDDlJaWSpJiY2PPer/P55PP5/Mvn3lH04eHP1VjX5OAnxdSiyYtVO04bo/RIJSdPK6Ssi/cHqNBCFWY9n/ykdtjmPf18WMqKed7Mhi+Ova1tn111O0xzDt9/GTA2wYULvPnz1dKSoratm2rpKQkSdJ7772n8PBw5ebmBjRIdXW1pk2bpoEDByoxMfGsj8nKylJmZmat9QWHPpC3onFAz4tv9Eu8Xt2bJ7g9RoOw5v1X5fG4PUXDsOb559W9xcVuj2FeaZtQ9e1ymdtjNAhr3tzG92QQnPKdDnjbgMIlMTFRBQUFevbZZ/2/+v+2227TmDFj1LhxYAGRnp6uPXv2aPPmzd/5mIyMDE2fPt2/fOzYMbVr1y6g5wMAAPYE/HtcIiIiNHHixKAMMWXKFL366qvauHGj2rZt+52P83q98nq9QXlOAABgT0DvKnr66af197//3b88c+ZMNW3aVAMGDNCnn35a5/04jqMpU6Zo9erVevPNN3XxxZx+AwAA3y2gcJkzZ47/JaEtW7YoOztbf/jDH9SiRQvdf//9dd5Penq6/va3vyknJ0dRUVEqKSlRSUmJjh8/HshYAACggQvopaKioiJ16tRJkrRmzRrdcsstuvvuuzVw4EBdffXVdd7PwoULJanWNkuXLtW4ceMCGQ0AADRgAYVLZGSkDh8+rISEBL3xxhv+C2bDw8PrdbbE4e23AACgHgIKl2HDhumuu+5Sr1699NFHH+n666+XJL3//vvq0KFDMOcDAADwC+galwULFig5OVlffvmlVq1apebNm0uS8vPzddtttwV1QAAAgDMCOuPStGlTZWdn11p/tl8OBwAAECx1Dpddu3YpMTFRjRo10q5du/7rY3v27HnOgwEAAPynOofLZZddppKSEsXFxemyyy6Tx+OpcXHtmWWPx6OqqqrzMiwAAPhxq3O4FBYWqmXLlv6vAQAAfmh1Dpf27duf9WsAAIAfSsCfVbRv3z49+uij2rt3rySpW7duuvfee9WlS5egDQcAAPBtAb0detWqVUpMTFR+fr6SkpKUlJSkHTt2KDExUatWrQr2jAAAAJICPOMyc+ZMZWRk6Le//W2N9bNnz9bMmTN18803B2U4AACAbwvojEtxcbHuuOOOWuvHjh2r4uLicx4KAADgbAIKl6uvvlqbNm2qtX7z5s268sorz3koAACAswnopaIbbrhBs2bNUn5+vq644gpJ0tatW/X8888rMzNTL7/8co3HAgAABENA4TJ58mRJ0mOPPabHHnvsrPdJ4pfRAQCAoAooXKqrq4M9BwAAwPeq1zUu119/vUpLS/3Lc+fO1dGjR/3Lhw8fVvfu3YM2HAAAwLfVK1xyc3Pl8/n8y3PmzNGRI0f8y6dPn9a+ffuCNx0AAMC31Ctcvv2himdbBgAAOJ8Cejs0AACAG+oVLh6PRx6Pp9Y6AACAH0K93lXkOI7GjRsnr9crSTpx4oQmTZqkJk2aSFKN618AAACCrV7hkpaWVmN57NixtR5zto8CAAAACIZ6hcvSpUvP1xwAAADfi4tzAQCAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAww9Vw2bhxo0aMGKE2bdrI4/FozZo1bo4DAAAucK6GS0VFhZKSkrRgwQI3xwAAAEaEuvnkqampSk1NdXMEAABgiKvhUl8+n08+n8+/fOzYMRenAQAAPzRT4ZKVlaXMzMxa6/cdOajQE14XJmo4jp8+qSMnj7s9RoPgqz6tytOn3B6jQTjmq9QHXxW6PYZ5sXEddMTHz3cw+KqqOJZBcNoX+N+RpsIlIyND06dP9y8fO3ZM7dq1U5fYBHmbNHZxMvt2f12iqhCOYTCkdElRrDfC7TEajFgv35fnqkurRHVvcbHbYzQI/9Pj5/x8B0FFWZmu+8vqgLY1FS5er1deL2dWAAD4seL3uAAAADNcPeNSXl6u/fv3+5cLCwu1c+dOxcbGKiEhwcXJAADAhcjVcNm+fbsGDx7sXz5z/UpaWpqWLVvm0lQAAOBC5Wq4XH311XIcx80RAACAIVzjAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMAMwgUAAJhBuAAAADMIFwAAYAbhAgAAzCBcAACAGYQLAAAwg3ABAABmEC4AAMCMULcHOBeO40iSTlaecHkS+46XV6jCW+b2GA1Cpe+4vCer3B6jQThZeUK+025PYR8/38HDz3dwVJSVS/r/f8frw+MEstUF4uOPP9Yll1zi9hgAACAABw4cUMeOHeu1jekzLrGxsZKkgwcPKiYmxuVpbDt27JjatWunoqIiRUdHuz2OWRzH4OFYBg/HMjg4jsFTWlqqhIQE/7/j9WE6XBo1+uYSnZiYGL6JgiQ6OppjGQQcx+DhWAYPxzI4OI7Bc+bf8Xptcx7mAAAAOC8IFwAAYIbpcPF6vZo9e7a8Xq/bo5jHsQwOjmPwcCyDh2MZHBzH4DmXY2n6XUUAAODHxfQZFwAA8ONCuAAAADMIFwAAYAbhAgAAzDAdLgsWLFCHDh0UHh6u/v3765133nF7JHM2btyoESNGqE2bNvJ4PFqzZo3bI5mUlZWlvn37KioqSnFxcbrxxhu1b98+t8cyaeHCherZs6f/l3wlJyfrtddec3ss8+bOnSuPx6Np06a5PYo5Dz30kDweT41b165d3R7LrM8++0xjx45V8+bN1bhxY/30pz/V9u3b67y92XBZuXKlpk+frtmzZ2vHjh1KSkpSSkqKDh065PZoplRUVCgpKUkLFixwexTT8vLylJ6erq1bt2rt2rU6deqUrr32WlVUVLg9mjlt27bV3LlzlZ+fr+3bt+uaa67RyJEj9f7777s9mlnbtm3T448/rp49e7o9ilk9evRQcXGx/7Z582a3RzLp66+/1sCBA3XRRRfptdde0wcffKB58+apWbNmdd+JY1S/fv2c9PR0/3JVVZXTpk0bJysry8WpbJPkrF692u0xGoRDhw45kpy8vDy3R2kQmjVr5jzxxBNuj2FSWVmZc+mllzpr1651rrrqKmfq1Kluj2TO7NmznaSkJLfHaBBmzZrl/OxnPzunfZg843Ly5Enl5+dr6NCh/nWNGjXS0KFDtWXLFhcnA75RWloqSQF9gBj+X1VVlVasWKGKigolJye7PY5J6enpGj58eI2/L1F/BQUFatOmjTp27KgxY8bo4MGDbo9k0ssvv6w+ffro1ltvVVxcnHr16qUlS5bUax8mw+Wrr75SVVWVWrVqVWN9q1atVFJS4tJUwDeqq6s1bdo0DRw4UImJiW6PY9Lu3bsVGRkpr9erSZMmafXq1erevbvbY5mzYsUK7dixQ1lZWW6PYlr//v21bNkyvf7661q4cKEKCwt15ZVXqqyszO3RzPn444+1cOFCXXrppcrNzdU999yj++67T08//XSd92H606GBC1F6err27NnDa+DnoEuXLtq5c6dKS0v1wgsvKC0tTXl5ecRLPRQVFWnq1Klau3atwsPD3R7HtNTUVP/XPXv2VP/+/dW+fXs999xzmjBhgouT2VNdXa0+ffpozpw5kqRevXppz549WrRokdLS0uq0D5NnXFq0aKGQkBB98cUXNdZ/8cUXat26tUtTAdKUKVP06quvav369Wrbtq3b45gVFhamTp06qXfv3srKylJSUpLmz5/v9lim5Ofn69ChQ7r88ssVGhqq0NBQ5eXl6S9/+YtCQ0NVVVXl9ohmNW3aVJ07d9b+/fvdHsWc+Pj4Wv8B6datW71eejMZLmFhYerdu7fWrVvnX1ddXa1169bxOjhc4TiOpkyZotWrV+vNN9/UxRdf7PZIDUp1dbV8Pp/bY5gyZMgQ7d69Wzt37vTf+vTpozFjxmjnzp0KCQlxe0SzysvLdeDAAcXHx7s9ijkDBw6s9asiPvroI7Vv377O+zD7UtH06dOVlpamPn36qF+/fvrzn/+siooKjR8/3u3RTCkvL6/xv4bCwkLt3LlTsbGxSkhIcHEyW9LT05WTk6OXXnpJUVFR/mutYmJi1LhxY5ensyUjI0OpqalKSEhQWVmZcnJytGHDBuXm5ro9milRUVG1rrFq0qSJmjdvzrVX9TRjxgyNGDFC7du31+eff67Zs2crJCREt912m9ujmXP//fdrwIABmjNnjkaNGqV33nlHixcv1uLFi+u+k+C8wckdjz76qJOQkOCEhYU5/fr1c7Zu3er2SOasX7/ekVTrlpaW5vZoppztGEpyli5d6vZo5tx5551O+/btnbCwMKdly5bOkCFDnDfeeMPtsRoE3g4dmNGjRzvx8fFOWFiY85Of/MQZPXq0s3//frfHMuuVV15xEhMTHa/X63Tt2tVZvHhxvbb3OI7jBDmoAAAAzguT17gAAIAfJ8IFAACYQbgAAAAzCBcAAGAG4QIAAMwgXAAAgBmECwAAMINwAQAAZhAuAEzxeDxas2aN22MAcAnhAqCGoqIi3XnnnWrTpo3CwsLUvn17TZ06VYcPH/5B53jooYd02WWX1VpfXFys1NTU8/rcL774ooYNG6aWLVsqOjpaycnJfFYScIEgXAD4ffzxx+rTp48KCgq0fPly7d+/X4sWLfJ/8vqRI0fcHlGtW7eW1+s9r8+xceNGDRs2TP/4xz+Un5+vwYMHa8SIEXr33XfP6/MCqIPz8glKAEy67rrrnLZt2zqVlZU11hcXFzsRERHOpEmT/OskOatXr67xuJiYmBofLHnw4EHn1ltvdWJiYpxmzZo5N9xwg1NYWOi/f/369U7fvn2diIgIJyYmxhkwYIDzySefOEuXLv3OD6z8z+fdtWuXM3jwYCc8PNyJjY11Jk6c6JSVlfnvT0tLc0aOHOn88Y9/dFq3bu3ExsY6kydPdk6ePFmvY9O9e3cnMzOzXtsACD7OuACQJB05ckS5ubmaPHmyGjduXOO+1q1ba8yYMVq5cqWcOn4u66lTp5SSkqKoqCht2rRJb731liIjI3Xdddfp5MmTOn36tG688UZdddVV2rVrl7Zs2aK7775bHo9Ho0eP1gMPPKAePXqouLhYxcXFGj16dK3nqKioUEpKipo1a6Zt27bp+eef1z//+U9NmTKlxuPWr1+vAwcOaP369Xr66ae1bNkyLVu2rM7Hprq6WmVlZYqNja3zNgDOj1C3BwBwYSgoKJDjOOrWrdtZ7+/WrZu+/vprffnll4qLi/ve/a1cuVLV1dV64okn5PF4JElLly5V06ZNtWHDBvXp00elpaX6+c9/rksuucT/HGdERkYqNDRUrVu3/s7nyMnJ0YkTJ/TMM8+oSZMmkqTs7GyNGDFCv//979WqVStJUrNmzZSdna2QkBB17dpVw4cP17p16zRx4sQ6HZtHHnlE5eXlGjVqVJ0eD+D84YwLgBq+74xKWFhYnfbz3nvvaf/+/YqKilJkZKQiIyMVGxurEydO6MCBA4qNjdW4ceOUkpKiESNGaP78+SouLq7XrHv37lVSUpI/WiRp4MCBqq6u1r59+/zrevTooZCQEP9yfHy8Dh06VKfnyMnJUWZmpp577rk6BRuA84twASBJ6tSpkzwej/bu3XvW+/fu3auWLVuqadOmkr55W/J/Rs6pU6f8X5eXl6t3797auXNnjdtHH32k22+/XdI3Z2C2bNmiAQMGaOXKlercubO2bt0a9D/bRRddVGPZ4/Gourr6e7dbsWKF7rrrLj333HMaOnRo0OcCUH+ECwBJUvPmzTVs2DA99thjOn78eI37SkpK9Oyzz2rcuHH+dS1btqxxhqSgoECVlZX+5csvv1wFBQWKi4tTp06datxiYmL8j+vVq5cyMjL0r3/9S4mJicrJyZH0zZmdqqqq/zpzt27d9N5776miosK/7q233lKjRo3UpUuXgI7DGcuXL9f48eO1fPlyDR8+/Jz2BSB4CBcAftnZ2fL5fEpJSdHGjRtVVFSk119/XcOGDVPnzp31m9/8xv/Ya665RtnZ2Xr33Xe1fft2TZo0qcaZjTFjxqhFixYaOXKkNm3apMLCQm3YsEH33Xef/v3vf6uwsFAZGRnasmWLPv30U73xxhsqKCjwX+fSoUMHFRYWaufOnfrqq6/k8/lqzTtmzBiFh4crLS1Ne/bs0fr163XvvffqF7/4hf/6lkDk5OTojjvu0Lx589S/f3+VlJSopKREpaWlAe8TQHAQLgD8Lr30Um3btk0dO3bUqFGj1L59e6Wmpqpz587+dwWdMW/ePLVr105XXnmlbr/9ds2YMUMRERH++yMiIrRx40YlJCTopptuUrdu3TRhwgSdOHFC0dHRioiI0Icffqibb75ZnTt31t1336309HT98pe/lCTdfPPNuu666zR48GC1bNlSy5cvrzVvRESEcnNzdeTIEfXt21e33HKLhgwZouzs7HM6DosXL9bp06eVnp6u+Ph4/23q1KnntF8A587j1PW9jQB+lGbPnq0//elPWrt2ra644gq3xwHwI0e4APheS5cuVWlpqe677z41asSJWgDuIVwAAIAZ/NcJAACYQbgAAAAzCBcAAGAG4QIAAMwgXAAAgBmECwAAMINwAQAAZhAuAADADMIFAACY8X8J879iLAEtFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAG2CAYAAABYlw1sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAid0lEQVR4nO3de1TUdeL/8dcAMqDcFEUhRVPzSpJpGrJZaWbkunq66CZueNlcNyyNTGU7uyxtiXWqs/7CtKywNi0r0y57Cs1UtNVCDNPWu66xhlmZ3NRRZ+b3R6f5ysJuMDHz4d08H+dwTvNhmHl9RPPpMAM2t9vtFgAAgAGCrB4AAADQUIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMEazCZcFCxbIZrNp1qxZVk8BAADNVLMIl+LiYj3zzDPq16+f1VMAAEAzZnm4VFdXKz09XUuXLlXr1q2tngMAAJqxEKsHZGZmatSoUbrhhhv08MMP/8/rOhwOORwOz2WXy6WTJ08qNjZWNpvN11MBAEATcLvdqqqqUkJCgoKCGvcYiqXh8uqrr2rHjh0qLi5u0PXz8vKUm5vr41UAAMAfysrK1LFjx0Z9jGXhUlZWppkzZ2rdunUKCwtr0MdkZ2crKyvLc7miokKJiYma9fb/k71VuK+mNkuvv7pcl8XEWz3D75zd2mnAZZdbPcPvDp4qV/cA/Hxz3oGF8w4cjpoz+uuv7lVkZGSjP9aycCkpKdGJEyd05ZVXeo45nU4VFRUpPz9fDodDwcHBtT7GbrfLbrfXuS17q3DZI1r6fHNzEhwaohb2UKtn+F1QuD3gPteS1OJ8GOcdQDjvwBKo5y3Jq6d5WBYuw4cP165du2odmzx5snr16qW5c+fWiRYAAADLwiUyMlJJSUm1jrVq1UqxsbF1jgMAAEjN4OXQAAAADWX5y6EvtnHjRqsnAACAZoxHXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxLA2XxYsXq1+/foqKilJUVJRSUlL03nvvWTkJAAA0Y5aGS8eOHbVgwQKVlJRo+/btGjZsmMaMGaPPP//cylkAAKCZCrHyzkePHl3r8iOPPKLFixdr27Zt6tu3r0WrAABAc2VpuFzM6XTq9ddfV01NjVJSUqyeAwAAmiHLw2XXrl1KSUnR2bNnFRERodWrV6tPnz71XtfhcMjhcHguV1ZWSpJOnKlWaJDTL3ubC5fbJZfbbfUMv3M4L+ir01VWz/C7087znHcACdTzrjx3Rvu/O2b1DL+rOFcTcOd9vuas1x9rebj07NlTpaWlqqio0BtvvKGMjAxt2rSp3njJy8tTbm5uneMjOqeoZWSEP+Y2G3949NfqEB5p9Qy/+3vZPxVks1k9w++On6kKyM835x1Y3juyRe1bBt557//umHq0vsTqGX7laHHa64+1/OXQoaGh6t69uwYMGKC8vDwlJydr4cKF9V43OztbFRUVnreysjI/rwUAAFay/BGX/+RyuWp9Oehidrtddrvdz4sAAEBzYWm4ZGdnKy0tTYmJiaqqqtKKFSu0ceNGFRYWWjkLAAA0U5aGy4kTJ3TnnXeqvLxc0dHR6tevnwoLCzVixAgrZwEAgGbK0nB5/vnnrbx7AABgGMufnAsAANBQhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIzhdbhs3rxZEydOVEpKio4dOyZJ+tvf/qYtW7Y02TgAAICLeRUuq1at0siRIxUeHq5PP/1UDodDklRRUaH58+c36UAAAIAfeBUuDz/8sJYsWaKlS5eqRYsWnuOpqanasWNHk40DAAC4mFfhsm/fPg0dOrTO8ejoaJ06deqnbgIAAKiXV+HSoUMHHTx4sM7xLVu2qGvXrj95FAAAQH28Cpe77rpLM2fO1McffyybzaYvv/xSy5cv1+zZs/X73/++qTcCAABIkkK8+aB58+bJ5XJp+PDhOn36tIYOHSq73a7Zs2frnnvuaeqNAAAAkrwMF5vNpgcffFAPPPCADh48qOrqavXp00cRERFNvQ8AAMDDq3D5QWhoqPr06dNUWwAAAP6nBofLLbfc0uAbffPNN70aAwAA8L80+Mm50dHRnreoqCitX79e27dv97y/pKRE69evV3R0tE+GAgAANPgRl4KCAs9/z507V+PGjdOSJUsUHBwsSXI6nbr77rsVFRXV9CsBAADk5cuhX3jhBc2ePdsTLZIUHBysrKwsvfDCC002DgAA4GJehcuFCxe0d+/eOsf37t0rl8v1k0cBAADUx6tXFU2ePFlTp07VoUOHNGjQIEnSxx9/rAULFmjy5MlNOhAAAOAHXoXL448/rg4dOuiJJ55QeXm5JCk+Pl4PPPCA7r///iYdCAAA8AOvwiUoKEhz5szRnDlzVFlZKUk8KRcAAPjcT/oGdF9//bX27dsnSerVq5fatm3bJKMAAADq49WTc2tqajRlyhTFx8dr6NChGjp0qOLj4zV16lSdPn26qTcCAABI8jJcsrKytGnTJr3zzjs6deqUTp06pbfeekubNm1q1HNc8vLydNVVVykyMlJxcXEaO3as5xEcAACA/+RVuKxatUrPP/+80tLSFBUVpaioKN18881aunSp3njjjQbfzqZNm5SZmalt27Zp3bp1On/+vG688UbV1NR4MwsAAPzMefUcl9OnT6t9+/Z1jsfFxTXqS0Xvv/9+rcvLli1TXFycSkpKNHToUG+mAQCAnzGvwiUlJUU5OTl66aWXFBYWJkk6c+aMcnNzlZKS4vWYiooKSVKbNm3qfb/D4ZDD4fBc/uEVTV+drVZ4iNvr+zXRGed5HT9TZfUMvzvjPK+q844fv+LPTNW5M6pwVFo9w+9aBIcF7O/zQDzvyvNnVPFd4P0+r7lwTl+dDqzP97kzZ7z+WK/CZeHChRo5cqQ6duyo5ORkSdLOnTsVFhamwsJCr4a4XC7NmjVLqampSkpKqvc6eXl5ys3NrXO8fViEWoZHeHW/ptpYflAdwiOtnuF3VecdAXnenx7fqfYtA++8W9nbqkNkrNUz/O74maqA/H0e1SJc7VvGWT3D71rZ26pnzCVWz/Cr01XVKvjxq9XLq3BJSkrSgQMHtHz5cs+3/r/jjjuUnp6u8PBwr4ZkZmZq9+7d2rJly3+9TnZ2trKysjyXKysr1alTJ6/uDwAAmMfr7+PSsmVL3XXXXU0yYsaMGXr33XdVVFSkjh07/tfr2e122e32JrlPAABgHq9eVfTiiy/q73//u+fynDlzFBMToyFDhujo0aMNvh23260ZM2Zo9erV+vDDD3XppZd6MwcAAAQIr8Jl/vz5ni8Jbd26Vfn5+XrsscfUtm1b3XfffQ2+nczMTL388stasWKFIiMjdfz4cR0/flxnfsKTdgAAwM+XV18qKisrU/fu3SVJa9as0W233aZp06YpNTVV1113XYNvZ/HixZJU52MKCgo0adIkb6YBAICfMa/CJSIiQt9++60SExO1du1azxNmw8LCGvVoidsdWC9hBgAAP41X4TJixAj99re/Vf/+/bV//37dfPPNkqTPP/9cXbp0acp9AAAAHl49x2XRokVKSUnR119/rVWrVik29vvvs1BSUqI77rijSQcCAAD8wKtHXGJiYpSfn1/neH3fHA4AAKCpNDhcPvvsMyUlJSkoKEifffbZ/7xuv379fvIwAACA/9TgcLniiit0/PhxxcXF6YorrpDNZqv15NofLttsNjmdTp+MBQAAga3B4XLkyBG1a9fO898AAAD+1uBw6dy5c73/DQAA4C9e/6yiffv26amnntKePXskSb1799Y999yjnj17Ntk4AACAi3n1cuhVq1YpKSlJJSUlSk5OVnJysnbs2KGkpCStWrWqqTcCAABI8vIRlzlz5ig7O1sPPfRQreM5OTmaM2eObr311iYZBwAAcDGvHnEpLy/XnXfeWef4xIkTVV5e/pNHAQAA1MercLnuuuu0efPmOse3bNmia6655iePAgAAqI9XXyr61a9+pblz56qkpERXX321JGnbtm16/fXXlZubq7fffrvWdQEAAJqCV+Fy9913S5KefvppPf300/W+TxLfjA4AADQpr8LF5XI19Q4AAIAf1ajnuNx8882qqKjwXF6wYIFOnTrlufztt9+qT58+TTYOAADgYo0Kl8LCQjkcDs/l+fPn6+TJk57LFy5c0L59+5puHQAAwEUaFS4X/1DF+i4DAAD4klcvhwYAALBCo8LFZrPJZrPVOQYAAOAPjXpVkdvt1qRJk2S32yVJZ8+e1fTp09WqVStJqvX8FwAAgKbWqHDJyMiodXnixIl1rlPfjwIAAABoCo0Kl4KCAl/tAAAA+FE8ORcAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMYgXAAAgDEIFwAAYAzCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGsDRcioqKNHr0aCUkJMhms2nNmjVWzgEAAM2cpeFSU1Oj5ORkLVq0yMoZAADAECFW3nlaWprS0tKsnAAAAAxiabg0lsPhkMPh8FyurKy0cA0AAPA3o8IlLy9Pubm5dY4fqPhSYc5WFiyykC1YFY7AC7cL55z64otDVs/wu+9cVQH5+e7aJlz7Th2zeob/Beif74pzNQF53n3jYnTGecHqGX71U87XqHDJzs5WVlaW53JlZaU6deqk045v5WxxxsJl/rf/u2Pq0foSq2f43SsvFahnAJ6387I4XdXrCqtn+N3+kwcD8vd5oP75ltsZkOd9dVw39YwJrPOuCvc+UI0KF7vdLrvdbvUMAABgEb6PCwAAMIalj7hUV1fr4MGDnstHjhxRaWmp2rRpo8TERAuXAQCA5sjScNm+fbuuv/56z+Ufnr+SkZGhZcuWWbQKAAA0V5aGy3XXXSe3223lBAAAYBCe4wIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIxBuAAAAGMQLgAAwBiECwAAMAbhAgAAjEG4AAAAYxAuAADAGIQLAAAwBuECAACMQbgAAABjEC4AAMAYhAsAADAG4QIAAIwRYvWAn8LtdkuSHDVnLF7if+drzsrR4rTVM/zOee6CzjvOWT3D75xnHHJUB97nO1B/n3PegaWmqlpVQZVWz/Cr6qoqSf/393hj2NzefFQzcfjwYXXr1s3qGQAAwAuHDh1S165dG/UxRj/i0qZNG0nSF198oejoaIvX+E9lZaU6deqksrIyRUVFWT3HbzhvzjsQcN6cdyCoqKhQYmKi5+/xxjA6XIKCvn+KTnR0dEB9wn8QFRXFeQcQzjuwcN6BJVDP+4e/xxv1MT7YAQAA4BOECwAAMIbR4WK325WTkyO73W71FL/ivDnvQMB5c96BgPNu/Hkb/aoiAAAQWIx+xAUAAAQWwgUAABiDcAEAAMYgXAAAgDGMDpdFixapS5cuCgsL0+DBg/XJJ59YPcmnioqKNHr0aCUkJMhms2nNmjVWT/KLvLw8XXXVVYqMjFRcXJzGjh2rffv2WT3L5xYvXqx+/fp5vjFVSkqK3nvvPatn+dWCBQtks9k0a9Ysq6f43J///GfZbLZab7169bJ6ll8cO3ZMEydOVGxsrMLDw3X55Zdr+/btVs/yqS5dutT5fNtsNmVmZlo9zaecTqf++Mc/6tJLL1V4eLi6deumv/zlL436mUXGhsvKlSuVlZWlnJwc7dixQ8nJyRo5cqROnDhh9TSfqampUXJyshYtWmT1FL/atGmTMjMztW3bNq1bt07nz5/XjTfeqJqaGqun+VTHjh21YMEClZSUaPv27Ro2bJjGjBmjzz//3OppflFcXKxnnnlG/fr1s3qK3/Tt21fl5eWety1btlg9yee+++47paamqkWLFnrvvff0z3/+U0888YRat25t9TSfKi4urvW5XrdunSTp9ttvt3iZbz366KNavHix8vPztWfPHj366KN67LHH9NRTTzX8RtyGGjRokDszM9Nz2el0uhMSEtx5eXkWrvIfSe7Vq1dbPcMSJ06ccEtyb9q0yeopfte6dWv3c889Z/UMn6uqqnJfdtll7nXr1rmvvfZa98yZM62e5HM5OTnu5ORkq2f43dy5c92/+MUvrJ5huZkzZ7q7devmdrlcVk/xqVGjRrmnTJlS69gtt9ziTk9Pb/BtGPmIy7lz51RSUqIbbrjBcywoKEg33HCDtm7dauEy+ENFRYUkefXDuUzldDr16quvqqamRikpKVbP8bnMzEyNGjWq1p/xQHDgwAElJCSoa9euSk9P1xdffGH1JJ97++23NXDgQN1+++2Ki4tT//79tXTpUqtn+dW5c+f08ssva8qUKbLZbFbP8akhQ4Zo/fr12r9/vyRp586d2rJli9LS0hp8G0b+kMVvvvlGTqdT7du3r3W8ffv22rt3r0Wr4A8ul0uzZs1SamqqkpKSrJ7jc7t27VJKSorOnj2riIgIrV69Wn369LF6lk+9+uqr2rFjh4qLi62e4leDBw/WsmXL1LNnT5WXlys3N1fXXHONdu/ercjISKvn+czhw4e1ePFiZWVl6Q9/+IOKi4t17733KjQ0VBkZGVbP84s1a9bo1KlTmjRpktVTfG7evHmqrKxUr169FBwcLKfTqUceeUTp6ekNvg0jwwWBKzMzU7t37w6Ir/1LUs+ePVVaWqqKigq98cYbysjI0KZNm3628VJWVqaZM2dq3bp1CgsLs3qOX138L85+/fpp8ODB6ty5s1577TVNnTrVwmW+5XK5NHDgQM2fP1+S1L9/f+3evVtLliwJmHB5/vnnlZaWpoSEBKun+Nxrr72m5cuXa8WKFerbt69KS0s1a9YsJSQkNPjzbWS4tG3bVsHBwfrqq69qHf/qq6/UoUMHi1bB12bMmKF3331XRUVF6tixo9Vz/CI0NFTdu3eXJA0YMEDFxcVauHChnnnmGYuX+UZJSYlOnDihK6+80nPM6XSqqKhI+fn5cjgcCg4OtnCh/8TExKhHjx46ePCg1VN8Kj4+vk6I9+7dW6tWrbJokX8dPXpUH3zwgd58802rp/jFAw88oHnz5unXv/61JOnyyy/X0aNHlZeX1+BwMfI5LqGhoRowYIDWr1/vOeZyubR+/fqA+Pp/oHG73ZoxY4ZWr16tDz/8UJdeeqnVkyzjcrnkcDisnuEzw4cP165du1RaWup5GzhwoNLT01VaWhow0SJJ1dXVOnTokOLj462e4lOpqal1vr3B/v371blzZ4sW+VdBQYHi4uI0atQoq6f4xenTpxUUVDs9goOD5XK5GnwbRj7iIklZWVnKyMjQwIEDNWjQIP31r39VTU2NJk+ebPU0n6murq71r68jR46otLRUbdq0UWJiooXLfCszM1MrVqzQW2+9pcjISB0/flySFB0drfDwcIvX+U52drbS0tKUmJioqqoqrVixQhs3blRhYaHV03wmMjKyznOXWrVqpdjY2J/9c5pmz56t0aNHq3Pnzvryyy+Vk5Oj4OBg3XHHHVZP86n77rtPQ4YM0fz58zVu3Dh98sknevbZZ/Xss89aPc3nXC6XCgoKlJGRoZAQY/86bpTRo0frkUceUWJiovr27atPP/1UTz75pKZMmdLwG2niVzr51VNPPeVOTEx0h4aGugcNGuTetm2b1ZN8asOGDW5Jdd4yMjKsnuZT9Z2zJHdBQYHV03xqypQp7s6dO7tDQ0Pd7dq1cw8fPty9du1aq2f5XaC8HHr8+PHu+Ph4d2hoqPuSSy5xjx8/3n3w4EGrZ/nFO++8405KSnLb7XZ3r1693M8++6zVk/yisLDQLcm9b98+q6f4TWVlpXvmzJnuxMREd1hYmLtr167uBx980O1wOBp8Gza3uxHfrg4AAMBCRj7HBQAABCbCBQAAGINwAQAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcARrHZbFqzZo3VMwBYhHABUEtZWZmmTJmihIQEhYaGqnPnzpo5c6a+/fZbv+7485//rCuuuKLO8fLycqWlpfltx0cffaSQkJB6twDwP8IFgMfhw4c1cOBAHThwQK+88ooOHjyoJUuWeH7y+smTJ62eqA4dOshut/vlvk6dOqU777xTw4cP98v9AfhxhAsAj8zMTIWGhmrt2rW69tprlZiYqLS0NH3wwQc6duyYHnzwQc916/uSTUxMjJYtW+a5XFZWpnHjxikmJkZt2rTRmDFj9K9//cvz/o0bN2rQoEFq1aqVYmJilJqaqqNHj2rZsmXKzc3Vzp07ZbPZZLPZPLf7n/e7a9cuDRs2TOHh4YqNjdW0adNUXV3tef+kSZM0duxYPf7444qPj1dsbKwyMzN1/vz5H/31mD59uiZMmKCUlJRG/ToC8B3CBYAk6eTJkyosLNTdd9+t8PDwWu/r0KGD0tPTtXLlSjX057KeP39eI0eOVGRkpDZv3qyPPvpIERERuummm3Tu3DlduHBBY8eO1bXXXqvPPvtMW7du1bRp02Sz2TR+/Hjdf//96tu3r8rLy1VeXq7x48fXuY+amhqNHDlSrVu3VnFxsV5//XV98MEHmjFjRq3rbdiwQYcOHdKGDRv04osvatmyZbUCqz4FBQU6fPiwcnJyGnS+APwjxOoBAJqHAwcOyO12q3fv3vW+v3fv3vruu+/09ddfKy4u7kdvb+XKlXK5XHruuedks9kkfR8DMTEx2rhxowYOHKiKigr98pe/VLdu3Tz38YOIiAiFhISoQ4cO//U+VqxYobNnz+qll15Sq1atJEn5+fkaPXq0Hn30UbVv316S1Lp1a+Xn5ys4OFi9evXSqFGjtH79et11113/9ddi3rx52rx5s0JC+N8k0JzwiAuAWn7sEZXQ0NAG3c7OnTt18OBBRUZGKiIiQhEREWrTpo3Onj2rQ4cOqU2bNpo0aZJGjhyp0aNHa+HChSovL2/U1j179ig5OdkTLZKUmpoql8ulffv2eY717dtXwcHBnsvx8fE6ceJEvbfpdDo1YcIE5ebmqkePHo3aA8D3CBcAkqTu3bvLZrNpz5499b5/z549ateunWJiYiR9/1yT/4yci583Ul1drQEDBqi0tLTW2/79+zVhwgRJ3z8Cs3XrVg0ZMkQrV65Ujx49tG3btiY/txYtWtS6bLPZ5HK56r1uVVWVtm/frhkzZigkJEQhISF66KGHtHPnToWEhOjDDz9s8n0AGo5wASBJio2N1YgRI/T000/rzJkztd53/PhxLV++XJMmTfIca9euXa1HSA4cOKDTp097Ll955ZU6cOCA4uLi1L1791pv0dHRnuv1799f2dnZ+sc//qGkpCStWLFC0veP7Didzv+5uXfv3tq5c6dqamo8xz766CMFBQWpZ8+eXv06REVFadeuXbVia/r06erZs6dKS0s1ePBgr24XQNMgXAB45Ofny+FwaOTIkSoqKlJZWZnef/99jRgxQj169NCf/vQnz3WHDRum/Px8ffrpp9q+fbumT59e65GN9PR0tW3bVmPGjNHmzZt15MgRbdy4Uffee6/+/e9/68iRI8rOztbWrVt19OhRrV27VgcOHPA8z6VLly46cuSISktL9c0338jhcNTZm56errCwMGVkZGj37t3asGGD7rnnHv3mN7/xPL+lsYKCgpSUlFTrLS4uTmFhYUpKSqr1ZSkA/ke4APC47LLLVFxcrK5du2rcuHHq3Lmz0tLS1KNHD8+rgn7wxBNPqFOnTrrmmms0YcIEzZ49Wy1btvS8v2XLlioqKlJiYqJuueUW9e7dW1OnTtXZs2cVFRWlli1bau/evbr11lvVo0cPTZs2TZmZmfrd734nSbr11lt100036frrr1e7du30yiuv1NnbsmVLFRYW6uTJk7rqqqt02223afjw4crPz/f9LxYAS9jcDX1tI4CAlJOToyeffFLr1q3T1VdfbfUcAAGOcAHwowoKClRRUaF7771XQUE8UAvAOoQLAAAwBv90AgAAxiBcAACAMQgXAABgDMIFAAAYg3ABAADGIFwAAIAxCBcAAGAMwgUAABiDcAEAAMb4/70+P2ZAGh2eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ancr = sess.run([corrbool,locs, total_loss, logits, facts_0s, w_1]+attends+\n",
    "                [query, cs, question_module_outputs],feed_dict=validation_set)\n",
    "a = ancr[0]\n",
    "n = ancr[1]\n",
    "cr = ancr[2]\n",
    "attenders = np.array(ancr[6:-3]) \n",
    "faq = np.sum(ancr[4], axis=(-1,-2)) # Number of facts in each context\n",
    "\n",
    "limit = 5\n",
    "for question in range(min(limit, batch_size)):\n",
    "    plt.yticks(range(passes,0,-1))\n",
    "    plt.ylabel(\"Episode\")\n",
    "    plt.xlabel(\"Question \"+str(question+1))\n",
    "    pltdata = attenders[:,question,:int(faq[question]),0] \n",
    "    # Display only information about facts that actually exist, all others are 0\n",
    "    pltdata = (pltdata - pltdata.mean()) / ((pltdata.max() - pltdata.min() + 0.001)) * 256\n",
    "    plt.pcolor(pltdata, cmap=plt.cm.BuGn, alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "#print(list(map((lambda x: x.shape),ancr[3:])), new_ends.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5b81c2",
   "metadata": {},
   "source": [
    "In order to see what the answers for the above questions were, we can use the location of our distance score in the context as an index and see what word is at that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1eb541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:  bill picked up the milk there . bill dropped the milk . fred took the milk there . jeff travelled to the office . fred picked up the football there . fred passed the football to bill . bill gave the football to fred . fred travelled to the bedroom .\n",
      "QUESTION:  who gave the football ?\n",
      "RESPONSE:  fred Incorrect\n",
      "EXPECTED:  bill\n",
      "\n",
      "TEXT:  fred travelled to the garden . jeff took the milk there . bill journeyed to the kitchen . jeff passed the milk to bill . bill gave the milk to jeff . jeff passed the milk to bill .\n",
      "QUESTION:  who gave the milk ?\n",
      "RESPONSE:  fred Incorrect\n",
      "EXPECTED:  jeff\n",
      "\n",
      "TEXT:  jeff travelled to the bedroom . mary took the milk there . mary moved to the hallway . jeff journeyed to the office . mary picked up the football there . fred journeyed to the kitchen . fred got the apple there . fred put down the apple . fred journeyed to the bedroom . jeff travelled to the garden . jeff travelled to the bedroom . bill journeyed to the bathroom . fred went back to the office . bill went back to the hallway . mary gave the football to bill . bill passed the football to mary . jeff moved to the garden . mary passed the football to bill .\n",
      "QUESTION:  who gave the football ?\n",
      "RESPONSE:  mary Correct\n",
      "EXPECTED:  mary\n",
      "\n",
      "TEXT:  bill journeyed to the garden . mary went to the office . jeff grabbed the milk there . jeff passed the milk to bill . bill dropped the milk . fred travelled to the kitchen . mary moved to the bathroom . jeff moved to the hallway .\n",
      "QUESTION:  what did jeff give to bill ?\n",
      "RESPONSE:  milk Correct\n",
      "EXPECTED:  milk\n",
      "\n",
      "TEXT:  mary went to the office . jeff got the football there . fred moved to the bedroom . bill moved to the hallway . mary went to the hallway . jeff passed the football to mary . jeff travelled to the bedroom . mary went to the bathroom . fred went back to the garden . mary put down the football . mary went back to the bedroom . bill travelled to the bathroom . jeff grabbed the milk there . mary journeyed to the hallway . jeff left the milk . fred moved to the kitchen . fred went back to the office . jeff went to the office . bill went to the kitchen . bill journeyed to the office . mary went to the bathroom . fred went to the garden . jeff journeyed to the bathroom . jeff picked up the football there . jeff put down the football . jeff got the football there . fred went back to the kitchen . jeff handed the football to mary . mary discarded the football . fred moved to the bathroom .\n",
      "QUESTION:  what did jeff give to mary ?\n",
      "RESPONSE:  milk Incorrect\n",
      "EXPECTED:  football\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmc\\AppData\\Local\\Temp\\ipykernel_19188\\171307745.py:11: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  print (\"RESPONSE: \", cw[i], [\"Correct\", \"Incorrect\"][i!=e])\n"
     ]
    }
   ],
   "source": [
    "# Locations of responses within contexts\n",
    "indices = np.argmax(n,axis=1)\n",
    "\n",
    "# Locations of actual answers within contexts \n",
    "indicesc = np.argmax(a,axis=1)\n",
    "\n",
    "for i,e,cw, cqa in list(zip(indices, indicesc, val_context_words, val_cqas))[:limit]:\n",
    "    ccc = \" \".join(cw)\n",
    "    print(\"TEXT: \",ccc)\n",
    "    print (\"QUESTION: \", \" \".join(cqa[3]))\n",
    "    print (\"RESPONSE: \", cw[i], [\"Correct\", \"Incorrect\"][i!=e])\n",
    "    print(\"EXPECTED: \", cw[e])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe6146",
   "metadata": {},
   "source": [
    "Let’s keep training! In order to get good results, you may have to train for a long period of time (on my home desktop, it took about 12 hours), but you should eventually be able to reach very high accuracies (over 90%). Experienced users of Jupyter Notebook should note that at any time, you can interrupt training and still save the progress the network has made so far, as long as you keep the same tf.Session; this is useful if you want to visualize the attention and answers the network is currently giving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99231927",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(training_iterations_count, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2389d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final testing accuracy\n",
    "print(np.mean(sess.run([corrects], feed_dict= prep_batch(final_test_data))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8454bb",
   "metadata": {},
   "source": [
    "Once we’re done viewing what our model is returning, we can close the session to free up system resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3a982b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b8cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
